# Channel use case

## Use channels as Futures/Promises

Futures and promises are used in many other popular languages. They are often associated with requests and responses.

### Return receive-only channels as results

In the following example, the values of two arguments of the sumSquares function call are requested concurrently. Each of the two channel receive operations will block until a send operation performs on the corresponding channel.

```go
func longTimeRequest() <-chan int32 {
	r := make(chan int32)

	go func() {
		// Simulate a workload
		time.Sleep(time.Second * 3)
		r <- rand.Int31n(100)
	}()

	return r
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}

func main() {
	rand.Seed(time.Now().UnixNano())

	a, b := longTimeRequest(), longTimeRequest()

	fmt.Println(sumSquares(<-a, <-b))
}

```

### Pass send-only channels as argument

```go
func longTimeRequest(r chan<- int32) {
	// Simulate a workload
	time.Sleep(time.Second * 3)
	r <- rand.Int31n(100)
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}

func main() {
	now := time.Now()
	rand.Seed(time.Now().UnixNano())

	ra, rb := make(chan int32), make(chan int32)
	go longTimeRequest(ra)
	go longTimeRequest(rb)

	a, b := <-ra, <-rb
	fmt.Println(sumSquares(a, b), "after: ", time.Since(now))
}
```

## The first response wins

Sometimes, a piece of data can be received from several sources to avoid high latencies. To make the response duration as short as possible, we can send a request to every source in a separated goroutine. Only the first response will be used, other slower ones will be discarded.

Note, if there are N sources, the capacity of the communication channel must be at least N-1 to avoid the goroutines corresponding the discarded responses being blocked for ever.

```go
func send(c chan<- bool) {
	rand.Seed(time.Now().UnixNano())
	r := rand.Int31n(10) + 1
	time.Sleep(time.Second * time.Duration(r))
	c <- true
}

func main() {
	now := time.Now()
	ch := make(chan bool, 500)
	for i := 0; i < 500; i++ {
		go send(ch)
	}
	<-ch
	fmt.Println("after: ", time.Since(now))
}
```

```go
func source(c chan<- int32) {
	rb := rand.Intn(3) + 1
	time.Sleep(time.Duration(rb) * time.Second)
	select {
	case c <- int32(rb):
	default:
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())
	// Please note, the capacity of the channel must be at least one, so that the first send won't be 
	// missed if the receiver/request side has not gotten ready in time.
	c := make(chan int32, 1)
	for i := 0; i < 5; i++ {
		go source(c)
	}
	rnd := <-c
	fmt.Println(rnd)
}
```

```go

```
## Use Channels for Notifications

Notifications can be viewed as special requests/responses in which the responded values are not important.

### 1-to-1 notification by sending, or receiving a value to a channel


```go
func main() {
	now := time.Now()
	done := make(chan struct{})

	go func() {
		// simulate work load
		time.Sleep(time.Second * 2)
		// send notification
		done <- struct{}{}
	}()

	<-done
	fmt.Println("After: ", time.Since(now))
}
```

### N-to-1 and 1-to-N notification

**N-to-1 notification**

```go
func main() {
	now := time.Now()

	wg := sync.WaitGroup{}

	for i := 0; i < 5; i++ {
		wg.Add(1)

		go func() {
			// notifi ni -> 1
			defer wg.Done()
			// simulate workload
			time.Sleep(time.Second)
		}()
	}

	// block here
	wg.Wait()

	fmt.Println("after: ", time.Since(now))
}
```

**1-to-N notification**

We can close a channel to broadcast notifications. The feature that infinite values can be received from a closed channel will be utilized in many other use cases.

```go
func main() {
	now := time.Now()
	run := make(chan struct{})

	for i := 0; i < 5; i++ {
		go func(i int) {
			// block here
			<-run
			fmt.Println("Run: ", i, " after: ", time.Since(now))
		}(i)
	}

	time.Sleep(time.Second)
	close(run)
	time.Sleep(time.Second)
}
```

### Timer: scheduled notification

<- time.After(aDuration) will make the current goroutine enter blocking state, but time.Sleep(aDuration) function call will not. 

## Use Channels as Mutex Locks

One-capacity buffered channels can be used as one-time binary semaphore. In fact, such channels can also be used as multi-time binary semaphores. 

There are two manners to use one-capacity buffered channel as mutex locks.

1. Lock through a send, unlock through a receive
2. Lock through a receive, unlock through a send

The following is a lock-through-send example

```go
var _void = struct{}{}

func main() {
	// The capacity must be one
	mutex := make(chan struct{}, 1)

	counter := 0
	increase := func() {
		mutex <- _void
		counter++
		<-mutex
	}

	increase1000 := func(done chan<- struct{}) {
		for i := 0; i < 1000; i++ {
			increase()
		}
		done <- _void
	}

	done := make(chan struct{})
	go increase1000(done)
	go increase1000(done)
	<-done
	<-done
	fmt.Println(counter)
}

```

## Use channel as counting semaphores

Buffered channels can be used as counting semaphores. Counting semaphores can be viewed as multi-owner locks. If the capacity of a channel is N, then it can be viewed as a lock which can have most N owners at any time. Binary semaphores are special counting semaphores, each of binary semaphores can have at most one owner at any time. Binary semaphores (mutexes) are special counting semaphores, each of binary semaphores can have at most one owner at any time.

Counting semaphores are often used to enforce a maximum number of concurrent requests.

```go
type seat int
type bar chan seat

func (b bar) serveCustomer(c int) {
	log.Print("customer#", c, "enters the bar")
	// acquire lock
	seat := <-b
	log.Print("++ customer#", c, " drinks at seat#", seat)
	time.Sleep(time.Second * time.Duration(2+rand.Intn(5)))
	log.Println("-- customer#", c, " frees seat#", seat)
	// release log
	b <- seat
}

func main() {
	rand.Seed(time.Now().Unix())

	// the bar has 10 seats
	bar24x7 := make(bar, 10)
	// place seats in an bar
	for seatId := 0; seatId < cap(bar24x7); seatId++ {
		// None of the sends will block.
		// free seat
		bar24x7 <- seat(seatId)
	}

	for customerId := 0; ; customerId++ {
		time.Sleep(time.Second)
		go bar24x7.serveCustomer(customerId)
	}

	// sleeping != blocking
}
```

In the above example, only the customers each of whom get a seat can drink. So there will be most ten customers are drinking at any give time, there may be more than ten customers are served at the bar at the same time. Some customers are waiting for free seats. Although each customer goroutine consumes much fewer resources than a system thread, the total resources consumed by a large number of goroutines are not negligible. So it is best to create a customer goroutine only if there is an avaiable seat.

```go
// Seat ...
type Seat int

// Bar ...
type Bar chan Seat

// ServeCustomerAtSeat ...
func (bar Bar) ServeCustomerAtSeat(c int, seat Seat) {
	log.Print("++ customer#", c, " drinks at seat#", seat)
	time.Sleep(time.Second * time.Duration(2+rand.Intn(6)))
	log.Print("-- customer#", c, " frees seat#", seat)
	bar <- seat
}

func main() {
	rand.Seed(time.Now().UnixNano())

	bar27x7 := make(Bar, 10)
	for seatId := 0; seatId < cap(bar27x7); seatId++ {
		bar27x7 <- Seat(seatId)
	}

	for customerId := 0; ; customerId++ {
		time.Sleep(time.Second)
		seat := <-bar27x7
		go bar27x7.ServeCustomerAtSeat(customerId, seat)
	}
}
```
There will be at most ten live customer goroutines coexisting in the above optimized version (but there will still be a lots of customer goroutines to be created in the program lifetime).

In a more efficient implementation shown below, at most ten customer serving goroutines will be created in the program lifetime.

```go
type Seat int
type Bar chan Seat

func (bar Bar) ServeCustomerAtSeat(consumers chan int) {
	for c := range consumers {
		seatId := <-bar // acquire lock
		log.Print("++ customer#", c, " drinks at seat#", seatId)
		time.Sleep(time.Second * time.Duration(2+rand.Intn(6)))
		log.Print("-- customer#", c, " frees seat#", seatId)
		<-bar // release lock
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())

	bar24x7 := make(Bar, 10)
	for seatId := 0; seatId < cap(bar24x7); seatId++ {
		bar24x7 <- Seat(seatId)
	}

	consumers := make(chan int)
	for i := 0; i < cap(bar24x7); i++ {
		go bar24x7.ServeCustomerAtSeat(consumers)
	}

	for customerId := 0; ; customerId++ {
		consumers <- customerId
	}
}
```

Off-topic: surely, if we don't care about seat IDs (which is common in practice), the the bar24x7 semaphore is not essential at all:

```go
func ServeCustomerAtSeat(consumers chan int) {
	for c := range consumers {
		log.Print("++ customer#", c, " drinks at seat#")
		time.Sleep(time.Second * time.Duration(2+rand.Intn(6)))
		log.Print("-- customer#", c, " frees seat#")
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())

	consumers := make(chan int)
	for i := 0; i < 10; i++ {
		go ServeCustomerAtSeat(consumers)
	}

	for customerId := 0; ; customerId++ {
		consumers <- customerId
	}
}
```

## Dialogue (Ping-Pong)

Two goroutines can dialogue through a channel. The following is an example which will print a series of Fibonacci numbers.

## Channel Encapsulated in Channel

Sometimes, we can use a channel type as the element type of another channel type. 

```go
```

## Block the Current Goroutine Forever 

We can use a blank select block select{} to block the current goroutine for ever. This is the simplest use case of the select mechanism. Generally, select{} is used to prevent the main goroutine from exiting, for if the main goroutine exits, the whole program will also exit.

```go
func greeting() {
	for {
		log.Println("Hello world")
	}
}

func main() {
	go greeting()
	select {}
}
```
## Try-send and try-receive

A select block with one default branch and only one case branch is called a try-send or try-receive channel operation.

```go
func main() {
	type Book struct{ id int }
	bookshelf := make(chan Book, 3)

	for i := 0; i < cap(bookshelf)*2; i++ {
		select {
		case bookshelf <- Book{id: i}:
			fmt.Println("succeeded to put my book", i)
		default:
			fmt.Println("failed to put book")
		}
	}
	for i := 0; i < cap(bookshelf)*2; i++ {
		select {
		case book := <-bookshelf:
			fmt.Println("succeeded to get book: ", book.id)
		default:
			fmt.Println("failed to get book")
		}
	}
}
```

## Check if a channel is closed without blocking the current goroutine

The way to check if a channel is closed to used popularly in Go concurrent programming to check whether or not a notification has arrived. The notification will be sent by closing the channel in another goroutine.

```go
// stupid way
func IsClosed[T any](c chan T) bool {
	select {
	case <-c:
		return true
	default:
	}

	return false
}
```
## Peak/burst limiting

We can implement peak limiting by combining use channels as counting semaphores and try-send/try-receive. Peak-limit (or burst-limit) is often used to limit the number of concurrent requests without blocking any requests.

```go
// Can serve most 10 customers at the same time
bar24x7 := make(Bar, 10)
for customerId := 0; ; customerId++ {
	time.Sleep(time.Second)
	customer := Consumer{customerId}
	select {
		case bar24x7 <- customer: // try to enter the bar
			go bar24x7.ServeCustomer(customer)
		default:
			log.Print("customer#", customerId, " goes elsewhere")
	}
}
```

## Another way to implement the first-response-wins use case

```go
func source(c chan<- int32) {
	ra, rb := rand.Int31(), rand.Intn(3)+1
	// Sleep 1s, 2s, 3s
	time.Sleep(time.Duration(rb) * time.Second)
	select {
	case c <- ra:
	default:
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())

	// the capacity should be at least 1
	c := make(chan int32, 1)
	for i := 0; i < 5; i++ {
		go source(c)
	}

	rnd := <-c // only first response is used
	fmt.Println(rnd)
}

```
Please note, the capacity of the channel used in the above example must be at least one, so that the first send won't be missed if the receiver/request side has gotten ready in time. 